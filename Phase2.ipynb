{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "import torch.nn.functional as F # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "from torch_geometric.nn import global_mean_pool # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading CSV...\n",
      "ğŸ”¬ Processing molecules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14436/14436 [00:25<00:00, 563.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… loaded 14156 graph pairs\n",
      "âš ï¸ Skipped 280 invalid SMILES pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv_path   = \"pairs.csv\"\n",
    "\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "\n",
    "def fix_smiles(smiles):\n",
    "    return smiles.replace(\"N+[O-]\", \"[N+](=O)[O-]\")\n",
    "\n",
    "\n",
    "def atom_features(atom):\n",
    "    symbol = atom.GetSymbol()\n",
    "    one_hot = [\n",
    "        1.0 if symbol == \"H\" else 0.0,\n",
    "        1.0 if symbol == \"C\" else 0.0,\n",
    "        1.0 if symbol == \"N\" else 0.0,\n",
    "        1.0 if symbol == \"O\" else 0.0,\n",
    "        1.0 if symbol == \"F\" else 0.0\n",
    "    ]\n",
    "\n",
    "\n",
    "    \n",
    "    atomic_num = float(atom.GetAtomicNum())\n",
    "\n",
    "    formal_charge = float(atom.GetFormalCharge())\n",
    "\n",
    "    chirality_tag = float(int(atom.GetChiralTag()))\n",
    "\n",
    "    is_aromatic = 1.0 if atom.GetIsAromatic() else 0.0\n",
    "    is_in_ring  = 1.0 if atom.IsInRing() else 0.0\n",
    "\n",
    "    degree_minus_1 = float(atom.GetDegree() - 1)\n",
    "\n",
    "    feature_vector = (\n",
    "        one_hot\n",
    "        + [atomic_num]\n",
    "        + [formal_charge, chirality_tag, is_aromatic, is_in_ring]\n",
    "        + [degree_minus_1]\n",
    "    )\n",
    "    return torch.tensor(feature_vector, dtype=torch.float)\n",
    "\n",
    "\n",
    "def mol_to_graph(smiles: str):\n",
    "    smiles = fix_smiles(smiles)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        \n",
    "        x = torch.stack([atom_features(atom) for atom in mol.GetAtoms()])\n",
    "\n",
    "        \n",
    "        edge_index = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_index += [[i, j], [j, i]]\n",
    "\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        if edge_index.numel() == 0:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    except Exception:\n",
    "        return None  \n",
    "\n",
    "\n",
    "print(\"ğŸ”„ Loading CSV...\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "graph_pairs = []\n",
    "invalid_smiles = []\n",
    "\n",
    "label2id = {\n",
    "    \"ADHD\": 0,\n",
    "    \"Schizophrenia\": 1,\n",
    "    \"Epilepsy\": 2,\n",
    "    \"Supplement\": 3\n",
    "}\n",
    "\n",
    "print(\"ğŸ”¬ Processing molecules...\")\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    smiles1 = row[\"mol_1\"]\n",
    "    smiles2 = row[\"mol_2\"]\n",
    "    label = label2id[row[\"label\"]]  \n",
    "\n",
    "    g1 = mol_to_graph(smiles1)\n",
    "    g2 = mol_to_graph(smiles2)\n",
    "\n",
    "    if (g1 is None) or (g2 is None):\n",
    "        invalid_smiles.append((smiles1, smiles2))\n",
    "        continue\n",
    "\n",
    "    graph_pairs.append((g1, g2, label))\n",
    "\n",
    "print(f\"âœ… loaded {len(graph_pairs)} graph pairs\")\n",
    "\n",
    "\n",
    "if invalid_smiles:\n",
    "    print(f\"âš ï¸ Skipped {len(invalid_smiles)} invalid SMILES pairs\")\n",
    "    with open(\"invalid_smiles.txt\", \"w\") as f:\n",
    "        for s1, s2 in invalid_smiles:\n",
    "            f.write(f\"{s1},{s2}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecule 1: Data(x=[28, 11], edge_index=[2, 62])\n",
      "Molecule 2: Data(x=[30, 11], edge_index=[2, 66])\n",
      "Label: 1\n",
      "tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 7., 0., 0., 0., 1., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 1., 2.],\n",
      "        [0., 0., 1., 0., 0., 7., 0., 0., 1., 1., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 2.],\n",
      "        [0., 0., 1., 0., 0., 7., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 2.],\n",
      "        [0., 0., 0., 1., 0., 8., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 2.],\n",
      "        [0., 0., 0., 1., 0., 8., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 2.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 9., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g1, g2, label = graph_pairs[0]\n",
    "\n",
    "print(\"Molecule 1:\", g1)\n",
    "print(\"Molecule 2:\", g2)\n",
    "print(\"Label:\", label)\n",
    "\n",
    "print(g1.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        #change this\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key   = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.scale = hidden_dim ** 0.5\n",
    "\n",
    "    def forward(self, x_query, x_key_value):\n",
    "        #change this\n",
    "        Q = self.query(x_query)          \n",
    "        K = self.key(x_key_value)         \n",
    "        V = self.value(x_key_value)       \n",
    "\n",
    "        attn_scores  = torch.matmul(Q, K.T) / self.scale   \n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1) \n",
    "        attended     = torch.matmul(attn_weights, V)      \n",
    "        return attended\n",
    "\n",
    "class CrossAttentionGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "\n",
    "        self.cross_attention = CrossAttention(hidden_channels)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 4)  \n",
    "        )\n",
    "\n",
    "    def forward(self, data_a, data_b):\n",
    "        #change this\n",
    "        #change this\n",
    "        x1, edge_index1, batch1 = data_a.x, data_a.edge_index, data_a.batch\n",
    "        x2, edge_index2, batch2 = data_b.x, data_b.edge_index, data_b.batch\n",
    "\n",
    "        x1 = F.relu(self.gcn1(x1, edge_index1))\n",
    "        x1 = F.relu(self.gcn2(x1, edge_index1))\n",
    "\n",
    "        x2 = F.relu(self.gcn1(x2, edge_index2)) \n",
    "        x2 = F.relu(self.gcn2(x2, edge_index2))\n",
    "\n",
    "        \n",
    "        attn1 = self.cross_attention(x1, x2)  \n",
    "        attn2 = self.cross_attention(x2, x1)\n",
    "\n",
    "        \n",
    "        pooled1 = global_mean_pool(attn1, batch1)\n",
    "        pooled2 = global_mean_pool(attn2, batch2)\n",
    "\n",
    "        \n",
    "        combined = torch.cat([pooled1, pooled2], dim=1)\n",
    "\n",
    "       \n",
    "        out = self.classifier(combined)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IRANICA\\AppData\\Local\\Temp\\ipykernel_22736\\2119641410.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 13258.8658 | Train Acc: 52.70%\n",
      "Epoch 02 | Train Loss: 10154.1737 | Train Acc: 59.02%\n",
      "Epoch 03 | Train Loss: 9413.5295 | Train Acc: 61.60%\n",
      "Epoch 04 | Train Loss: 8957.9294 | Train Acc: 63.74%\n",
      "Epoch 05 | Train Loss: 6436.1289 | Train Acc: 76.75%\n",
      "Epoch 06 | Train Loss: 4159.5178 | Train Acc: 85.07%\n",
      "Epoch 07 | Train Loss: 3164.8158 | Train Acc: 89.07%\n",
      "Epoch 08 | Train Loss: 2763.0171 | Train Acc: 90.45%\n",
      "Epoch 09 | Train Loss: 2343.3876 | Train Acc: 91.98%\n",
      "Epoch 10 | Train Loss: 2074.6182 | Train Acc: 93.22%\n",
      "âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IRANICA\\AppData\\Local\\Temp\\ipykernel_22736\\2119641410.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ADHD       0.95      0.76      0.85       216\n",
      "Schizophrenia       0.99      0.99      0.99       620\n",
      "     Epilepsy       0.95      0.97      0.96      1436\n",
      "   Supplement       0.93      0.95      0.94       560\n",
      "\n",
      "     accuracy                           0.95      2832\n",
      "    macro avg       0.95      0.92      0.93      2832\n",
      " weighted avg       0.95      0.95      0.95      2832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def custom_collate(batch):\n",
    "    data_a_list, data_b_list, labels = zip(*batch)\n",
    "    batch_a = Batch.from_data_list(data_a_list)\n",
    "    batch_b = Batch.from_data_list(data_b_list)\n",
    "    labels = torch.tensor([int(l) if isinstance(l, str) else l for l in labels])  #\n",
    "    return batch_a, batch_b, labels\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(graph_pairs))\n",
    "train_set, test_set = torch.utils.data.random_split(graph_pairs, [train_size, len(graph_pairs) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=16, collate_fn=custom_collate)\n",
    "\n",
    "\n",
    "model = CrossAttentionGNN(in_channels=11, hidden_channels=100)  #change this\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#change this\n",
    "criterion = torch.nn.CrossEntropyLoss() #change this\n",
    "\n",
    "\n",
    "for epoch in range(1, 11): \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #complete this\n",
    "    for batch in train_loader:\n",
    "        data_a, data_b, labels = batch\n",
    "        data_a = data_a.to(device)\n",
    "        data_b = data_b.to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_a, data_b)  \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {total_loss:.4f} | Train Acc: {acc:.2%}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "torch.save(model.state_dict(), \"trained_cross_attention_gnn.pth\")\n",
    "print(\"âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    #complete this\n",
    "    for batch in test_loader:\n",
    "        data_a, data_b, labels = batch\n",
    "        data_a = data_a.to(device)\n",
    "        data_b = data_b.to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        outputs = model(data_a, data_b)  \n",
    "        preds = outputs.argmax(dim=1)   \n",
    "\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "# === Classification Report ===\n",
    "id2label = {0: \"ADHD\", 1: \"Schizophrenia\", 2: \"Epilepsy\", 3: \"Supplement\"}\n",
    "print(classification_report(all_labels, all_preds, target_names=[id2label[i] for i in range(4)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
