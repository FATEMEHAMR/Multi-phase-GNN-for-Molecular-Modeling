{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0d31dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0544f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zscore_sample(sample: np.ndarray):\n",
    "    mu = sample.mean(axis=0, keepdims=True)\n",
    "    sigma = sample.std(axis=0, keepdims=True)\n",
    "    sigma[sigma < 1e-6] = 1.0\n",
    "    return (sample - mu) / sigma\n",
    "\n",
    "def eeg_row_to_graph(channel_features, connectivity_threshold=0.6, knn_fallback=4):\n",
    "    if channel_features is None or channel_features.shape[0] == 0:\n",
    "        return None\n",
    "    X = np.array(channel_features, dtype=np.float32)\n",
    "    Xz = zscore_sample(X)\n",
    "    num_nodes = Xz.shape[0]\n",
    "    x = torch.tensor(Xz, dtype=torch.float)\n",
    "\n",
    "    corr_matrix = pd.DataFrame(Xz).T.corr(method='pearson').fillna(0.0).values\n",
    "    edges, weights = [], []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            w = float(abs(corr_matrix[i, j]))\n",
    "            if w > connectivity_threshold:\n",
    "                edges.append([i, j]); edges.append([j, i])\n",
    "                weights.append(w); weights.append(w)\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        Xn = Xz / (np.linalg.norm(Xz, axis=1, keepdims=True) + 1e-8)\n",
    "        S = np.matmul(Xn, Xn.T)\n",
    "        np.fill_diagonal(S, -1.0)\n",
    "        k = min(knn_fallback, max(1, num_nodes - 1))\n",
    "        for i in range(num_nodes):\n",
    "            nbrs = np.argpartition(-S[i], k)[:k]\n",
    "            for j in nbrs:\n",
    "                if j >= 0:\n",
    "                    w = max(0.0, float(S[i, j]))\n",
    "                    edges.append([i, j]); weights.append(w)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_attr  = torch.tensor(weights, dtype=torch.float).unsqueeze(-1) if weights else torch.empty((0, 1), dtype=torch.float)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "_ATOM_ORDER = [\"C\",\"N\",\"O\",\"S\",\"F\",\"Cl\",\"Br\",\"I\",\"P\",\"Si\"]\n",
    "def atom_feature_11(atom: Chem.Atom):\n",
    "    sym = atom.GetSymbol()\n",
    "    vec = [0.0]*11\n",
    "    if sym in _ATOM_ORDER:\n",
    "        vec[_ATOM_ORDER.index(sym)] = 1.0\n",
    "    else:\n",
    "        vec[-1] = 1.0  \n",
    "    return vec\n",
    "\n",
    "def mol_to_graph(smiles: str):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "\n",
    "    num_atoms = mol.GetNumAtoms()\n",
    "    if num_atoms == 0:\n",
    "        return None\n",
    "\n",
    "    X = []\n",
    "    for a in mol.GetAtoms():\n",
    "        X.append(atom_feature_11(a))\n",
    "    x = torch.tensor(X, dtype=torch.float)\n",
    "\n",
    "    edges = []\n",
    "    for b in mol.GetBonds():\n",
    "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
    "        edges.append([i, j]); edges.append([j, i])\n",
    "    if len(edges) == 0:\n",
    "        edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce27468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key   = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.scale = hidden_dim ** 0.5\n",
    "\n",
    "    def forward(self, x_query, x_key_value):\n",
    "        Q = self.query(x_query)\n",
    "        K = self.key(x_key_value)\n",
    "        V = self.value(x_key_value)\n",
    "        attn_scores  = torch.matmul(Q, K.T) / self.scale\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attended     = torch.matmul(attn_weights, V)\n",
    "        return attended\n",
    "\n",
    "class CrossAttentionGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    دقیقا مطابق Phase2.ipynb:\n",
    "      - دو لایه GCN با اسامی gcn1/gcn2\n",
    "      - ماژول cross_attention\n",
    "      - classifier انتهایی (۴-کلاسه)\n",
    "    بعلاوه: یک متد کمکی encode_pair برای گرفتن امبدینگ زوج قبل از کلاس‌فایر\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.cross_attention = CrossAttention(hidden_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 4)\n",
    "        )\n",
    "\n",
    "    def encode_single(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.gcn1(x, edge_index))\n",
    "        x = F.relu(self.gcn2(x, edge_index))\n",
    "        return x, batch  \n",
    "\n",
    "    def encode_pair(self, data_a, data_b):\n",
    "        x1, batch1 = self.encode_single(data_a)\n",
    "        x2, batch2 = self.encode_single(data_b)\n",
    "        attn1 = self.cross_attention(x1, x2)\n",
    "        attn2 = self.cross_attention(x2, x1)\n",
    "        pooled1 = global_mean_pool(attn1, batch1)\n",
    "        pooled2 = global_mean_pool(attn2, batch2)\n",
    "        combined = torch.cat([pooled1, pooled2], dim=1)  \n",
    "        return combined\n",
    "\n",
    "    def forward(self, data_a, data_b):\n",
    "        combined = self.encode_pair(data_a, data_b)\n",
    "        out = self.classifier(combined)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fde537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained Phase 2 model from: ../Phase 2/trained_cross_attention_gnn.pth\n",
      "[Phase2] inferred hidden_dim=100, in_channels=11\n",
      "Drug embeddings shape: (4, 128)\n",
      "[Phase2] Using hidden_dim=100, in_channels=11\n",
      "[Phase2] Using hidden_dim=100, in_channels=11\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PHASE2_CKPT = \"../Phase 2/trained_cross_attention_gnn.pth\"\n",
    "\n",
    "def infer_dims_from_state(state):\n",
    "    \"\"\"حدس hidden_dim و in_channels از روی state_dict چک‌پوینت.\"\"\"\n",
    "    hidden = None\n",
    "   \n",
    "    for k in [\"cross_attention.query.weight\", \"cross_attention.value.weight\", \"cross_attention.key.weight\"]:\n",
    "        if k in state:\n",
    "            w = state[k]\n",
    "            hidden = w.shape[0]\n",
    "            break\n",
    "\n",
    "    in_ch = None\n",
    "    for k in [\"gcn1.lin_l.weight\", \"gcn1.lin.weight\"]:\n",
    "        if k in state:\n",
    "            w = state[k] \n",
    "            in_ch = w.shape[1]\n",
    "            break\n",
    "\n",
    "    return hidden, in_ch\n",
    "\n",
    "def load_phase2_model_smart(model_path, device):\n",
    "    if not os.path.isfile(model_path):\n",
    "        raise FileNotFoundError(f\"Phase2 checkpoint not found: {model_path}\")\n",
    "    print(f\"Loading trained Phase 2 model from: {model_path}\")\n",
    "    state = torch.load(model_path, map_location=device)\n",
    "\n",
    "    hidden_dim, in_channels = infer_dims_from_state(state)\n",
    "    if hidden_dim is None:\n",
    "        raise RuntimeError(\"Could not infer hidden_dim from checkpoint (cross_attention.* not found).\")\n",
    "    if in_channels is None:\n",
    "        in_channels = 11\n",
    "        print(f\"[WARN] Could not infer in_channels from checkpoint. Falling back to {in_channels}.\")\n",
    "\n",
    "    print(f\"[Phase2] inferred hidden_dim={hidden_dim}, in_channels={in_channels}\")\n",
    "\n",
    "    model = CrossAttentionGNN(in_channels=in_channels, hidden_channels=hidden_dim)\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    if missing:\n",
    "        print(\"[Phase2] missing keys:\", missing)\n",
    "    if unexpected:\n",
    "        print(\"[Phase2] unexpected keys:\", unexpected)\n",
    "\n",
    "    model.to(device).eval()\n",
    "    projector = nn.Linear(2 * hidden_dim, 128).to(device)\n",
    "    return model, projector, hidden_dim, in_channels\n",
    "\n",
    "phase2_model, proj_pair_to_128, HIDDEN_PHASE2, IN_CH_PHASE2 = load_phase2_model_smart(PHASE2_CKPT, device)\n",
    "pairs_df = pd.read_csv(\"../Phase 2/pairs.csv\")\n",
    "label_map = {\"ADHD\": 0, \"Schizophrenia\": 1, \"Epilepsy\": 2, \"Supplement\": 3}\n",
    "num_classes = len(label_map)\n",
    "\n",
    "@torch.no_grad()\n",
    "def pair_embedding(smiles_a, smiles_b):\n",
    "    g1 = mol_to_graph(smiles_a)\n",
    "    g2 = mol_to_graph(smiles_b)\n",
    "    if g1 is None or g2 is None:\n",
    "        return None\n",
    "    data_a = Batch.from_data_list([g1]).to(device)\n",
    "    data_b = Batch.from_data_list([g2]).to(device)\n",
    "    combined = phase2_model.encode_pair(data_a, data_b) \n",
    "    z = proj_pair_to_128(combined)                       \n",
    "    z = F.normalize(z, p=2, dim=-1)\n",
    "    return z.squeeze(0) \n",
    "\n",
    "drug_embeddings = torch.zeros((num_classes, 128), device=device)\n",
    "\n",
    "for name, idx in label_map.items():\n",
    "    rows = pairs_df[pairs_df['label'] == name]\n",
    "    if rows.empty:\n",
    "        print(f\"[WARN] No row for {name} in pairs.csv\")\n",
    "        continue\n",
    "    row = rows.iloc[0]\n",
    "    z = pair_embedding(row['mol_1'], row['mol_2'])\n",
    "    if z is None:\n",
    "        print(f\"[WARN] RDKit failed for {name}\")\n",
    "        continue\n",
    "    drug_embeddings[idx] = z\n",
    "\n",
    "print(\"Drug embeddings shape:\", tuple(drug_embeddings.shape))\n",
    "print(f\"[Phase2] Using hidden_dim={HIDDEN_PHASE2}, in_channels={IN_CH_PHASE2}\")\n",
    "print(f\"[Phase2] Using hidden_dim={HIDDEN_PHASE2}, in_channels={IN_CH_PHASE2}\")\n",
    "assert IN_CH_PHASE2 == 11, f\"Phase2 expects {IN_CH_PHASE2} features per atom; adapt atom_feature_11 accordingly!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e2ed974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DrugBank] Loaded cached bank: Z(13818, 128) | classes=['Schizophrenia', 'ADHD', 'Epilepsy', 'Supplement']\n"
     ]
    }
   ],
   "source": [
    "import os, json, torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def build_drug_bank_quiet(pairs_df, device,\n",
    "                          invalid_path=\"outputs_phase3/invalid_smiles.txt\"):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      Z: [M, 128] L2-normalized embeddings for all candidate drug pairs\n",
    "      meta: list of dicts with keys: idx, label, mol1, mol2\n",
    "      label_to_indices: dict label -> list of indices in Z\n",
    "    Writes:\n",
    "      invalid_path: one invalid pair per line (idx \\t mol1 \\t mol2)\n",
    "    \"\"\"\n",
    "    os.makedirs(\"outputs_phase3\", exist_ok=True)\n",
    "\n",
    "    Z_list, meta = [], []\n",
    "    label_to_indices = {}\n",
    "    invalid = []\n",
    "\n",
    "    for idx, row in pairs_df.iterrows():\n",
    "        smi1, smi2 = row[\"mol_1\"], row[\"mol_2\"]\n",
    "        lab = str(row[\"label\"])\n",
    "\n",
    "        z = None\n",
    "        try:\n",
    "            z = pair_embedding(smi1, smi2) \n",
    "        except Exception:\n",
    "            z = None\n",
    "\n",
    "        if (z is None) or (torch.isnan(z).any()):\n",
    "            invalid.append((int(idx), smi1, smi2))\n",
    "            continue\n",
    "\n",
    "        z = F.normalize(z.to(device, dtype=torch.float), p=2, dim=-1)\n",
    "        Z_list.append(z.unsqueeze(0))\n",
    "        meta.append({\"idx\": int(idx), \"label\": lab, \"mol1\": smi1, \"mol2\": smi2})\n",
    "        label_to_indices.setdefault(lab, []).append(len(Z_list) - 1)\n",
    "\n",
    "    if not Z_list:\n",
    "        raise RuntimeError(\"No valid drug embeddings built from pairs.csv\")\n",
    "\n",
    "    Z = torch.cat(Z_list, dim=0).to(device)  \n",
    "\n",
    "    with open(invalid_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, a, b in invalid:\n",
    "            f.write(f\"{i}\\t{a}\\t{b}\\n\")\n",
    "\n",
    "    print(f\"[DrugBank] Built {Z.size(0)} embeddings; skipped {len(invalid)} invalid pairs \"\n",
    "          f\"out of {len(pairs_df)} total.\")\n",
    "\n",
    "    return Z, meta, label_to_indices\n",
    "\n",
    "z_path   = \"outputs_phase3/drug_bank_Z.pt\"\n",
    "meta_path= \"outputs_phase3/drug_bank_meta.json\"\n",
    "l2i_path = \"outputs_phase3/drug_bank_label_to_indices.json\"\n",
    "\n",
    "if os.path.exists(z_path) and os.path.exists(meta_path) and os.path.exists(l2i_path):\n",
    "    Z = torch.load(z_path, map_location=device)\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    with open(l2i_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        label_to_indices = json.load(f)\n",
    "    print(f\"[DrugBank] Loaded cached bank: Z{tuple(Z.shape)} | classes={list(label_to_indices.keys())}\")\n",
    "else:\n",
    "    Z, meta, label_to_indices = build_drug_bank_quiet(pairs_df, device)\n",
    "    torch.save(Z, z_path)\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "    with open(l2i_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(label_to_indices, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "903ad5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EEG] adhd: built 20400 graphs | skipped healthy: 20400 | failed: 0 | channels: 14\n",
      "[EEG] sch: built 2700 graphs | skipped healthy: 2340 | failed: 0 | channels: 18\n",
      "[EEG] epi: built 3423 graphs | skipped healthy: 3423 | failed: 0 | channels: 21\n",
      "[Phase3] Total EEG graphs (disease-only): 26523\n"
     ]
    }
   ],
   "source": [
    "CANONICAL_CHANNELS = [\n",
    "    \"FP1\",\"FP2\",\"AF3\",\"AF4\",\"F7\",\"F3\",\"FZ\",\"F4\",\"F8\",\n",
    "    \"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"FT9\",\"FT10\",\n",
    "    \"FC5\",\"FC6\",\"C3\",\"CZ\",\"C4\",\n",
    "    \"P7\",\"P3\",\"PZ\",\"P4\",\"P8\",\n",
    "    \"O1\",\"O2\"\n",
    "]\n",
    "\n",
    "NODE_FEATURE_SUFFIXES = [\n",
    "    \"mean\",\"std\",\"entropy\",\"hjorth_mobility\",\n",
    "    \"delta_power\",\"theta_power\",\"alpha_power\",\"beta_power\",\"gamma_power\"\n",
    "]\n",
    "\n",
    "LEGACY_TO_MODERN = {\"T3\":\"T7\",\"T4\":\"T8\",\"T5\":\"P7\",\"T6\":\"P8\"}  \n",
    "\n",
    "def _detect_channels(df: pd.DataFrame, dataset_tag: str):\n",
    "    chs = []\n",
    "    for ch in CANONICAL_CHANNELS:\n",
    "        if dataset_tag == \"sch\":\n",
    "            cand = [ch] + [k for k,v in LEGACY_TO_MODERN.items() if v == ch]\n",
    "            ok = any(f\"{c}_mean\" in df.columns for c in cand)\n",
    "        else:\n",
    "            ok = f\"{ch}_mean\" in df.columns\n",
    "        if ok:\n",
    "            chs.append(ch)\n",
    "    return chs\n",
    "\n",
    "def _row_to_matrix(row: pd.Series, channels, dataset_tag: str):\n",
    "    feats = []\n",
    "    for ch in channels:\n",
    "        vals = []\n",
    "        for suf in NODE_FEATURE_SUFFIXES:\n",
    "            col = f\"{ch}_{suf}\"\n",
    "            val = row[col] if col in row else None\n",
    "            if val is None and dataset_tag == \"sch\":\n",
    "                legacy = next((k for k,v in LEGACY_TO_MODERN.items() if v == ch), None)\n",
    "                if legacy is not None:\n",
    "                    col2 = f\"{legacy}_{suf}\"\n",
    "                    if col2 in row: val = row[col2]\n",
    "            if val is None or pd.isna(val) or np.isinf(val):\n",
    "                val = 0.0\n",
    "            vals.append(float(val))\n",
    "        feats.append(vals)\n",
    "    X = np.array(feats, dtype=np.float32)  \n",
    "    return X\n",
    "\n",
    "def read_eeg_csv_to_graphs(csv_path: str, dataset_tag: str, class_id: int):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    id_col = \"subject_id\" if \"subject_id\" in df.columns else (\"file\" if \"file\" in df.columns else None)\n",
    "    channels = _detect_channels(df, dataset_tag)\n",
    "    graphs, removed_healthy, failed = [], 0, 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if int(row[\"label\"]) == 0:\n",
    "            removed_healthy += 1\n",
    "            continue\n",
    "        X = _row_to_matrix(row, channels, dataset_tag)\n",
    "        g = eeg_row_to_graph(X, connectivity_threshold=0.6, knn_fallback=6)\n",
    "        if g is None: \n",
    "            failed += 1; continue\n",
    "        g.y = torch.tensor([class_id], dtype=torch.long)\n",
    "        uid = str(row[id_col]) if id_col and id_col in row else f\"{dataset_tag}_unknown\"\n",
    "        g.uid = uid\n",
    "        graphs.append(g)\n",
    "\n",
    "    print(f\"[EEG] {dataset_tag}: built {len(graphs)} graphs | skipped healthy: {removed_healthy} | failed: {failed} | channels: {len(channels)}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "\n",
    "ADHD_CSV = \"adhd.csv\"\n",
    "SCH_CSV  = \"sch.csv\"\n",
    "EPI_CSV  = \"epi.csv\"\n",
    "\n",
    "PH3_LABELS = {\"adhd\":0, \"sch\":1, \"epi\":2}\n",
    "\n",
    "all_graphs = []\n",
    "if os.path.isfile(ADHD_CSV):\n",
    "    all_graphs += read_eeg_csv_to_graphs(ADHD_CSV, \"adhd\", PH3_LABELS[\"adhd\"])\n",
    "if os.path.isfile(SCH_CSV):\n",
    "    all_graphs += read_eeg_csv_to_graphs(SCH_CSV, \"sch\",  PH3_LABELS[\"sch\"])\n",
    "if os.path.isfile(EPI_CSV):\n",
    "    all_graphs += read_eeg_csv_to_graphs(EPI_CSV, \"epi\",  PH3_LABELS[\"epi\"])\n",
    "\n",
    "print(f\"[Phase3] Total EEG graphs (disease-only): {len(all_graphs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31b75044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split] sizes: 21081 2721 2721\n",
      "[Dist] train: [16200  2160  2721]\n",
      "[Dist] val  : [2100  270  351]\n",
      "[Dist] test : [2100  270  351]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold, train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def has_all(idxs, y, ncls=3):\n",
    "    bc = np.bincount(y[idxs], minlength=ncls)\n",
    "    return (bc > 0).all(), bc\n",
    "\n",
    "groups = np.array([g.uid for g in all_graphs])\n",
    "y = np.array([int(g.y.item()) for g in all_graphs])\n",
    "idx = np.arange(len(all_graphs))\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "picked = None\n",
    "for tr_idx, te_idx in sgkf.split(idx, y=y, groups=groups):\n",
    "    \n",
    "    va_idx, ts_idx = train_test_split(te_idx, test_size=0.5, random_state=42, stratify=y[te_idx])\n",
    "\n",
    "    ok_tr, bc_tr = has_all(tr_idx, y)\n",
    "    ok_va, bc_va = has_all(va_idx, y)\n",
    "    ok_ts, bc_ts = has_all(ts_idx, y)\n",
    "\n",
    "    if ok_tr and ok_va and ok_ts:\n",
    "        picked = (tr_idx, va_idx, ts_idx)\n",
    "        break\n",
    "\n",
    "\n",
    "if picked is None:\n",
    "    for tr_idx, te_idx in sgkf.split(idx, y=y, groups=groups):\n",
    "        for shift in [0, len(te_idx)//5, len(te_idx)//3, len(te_idx)//2]:\n",
    "            te2 = np.roll(te_idx, shift=shift)\n",
    "            va_idx, ts_idx = train_test_split(te2, test_size=0.5, random_state=42, stratify=y[te2])\n",
    "            ok_tr, bc_tr = has_all(tr_idx, y)\n",
    "            ok_va, bc_va = has_all(va_idx, y)\n",
    "            ok_ts, bc_ts = has_all(ts_idx, y)\n",
    "            if ok_tr and ok_va and ok_ts:\n",
    "                picked = (tr_idx, va_idx, ts_idx)\n",
    "                break\n",
    "        if picked is not None:\n",
    "            break\n",
    "\n",
    "if picked is None:\n",
    "    raise RuntimeError(\"Could not find a split with all classes in train/val/test. Check group/labels.\")\n",
    "\n",
    "train_idx, val_idx, test_idx = picked\n",
    "\n",
    "def subset(idxs): return [all_graphs[i] for i in idxs]\n",
    "train_graphs = subset(train_idx)\n",
    "val_graphs   = subset(val_idx)\n",
    "test_graphs  = subset(test_idx)\n",
    "\n",
    "print(\"[Split] sizes:\", len(train_graphs), len(val_graphs), len(test_graphs))\n",
    "print(\"[Dist] train:\", np.bincount([int(g.y.item()) for g in train_graphs], minlength=3))\n",
    "print(\"[Dist] val  :\", np.bincount([int(g.y.item()) for g in val_graphs],   minlength=3))\n",
    "print(\"[Dist] test :\", np.bincount([int(g.y.item()) for g in test_graphs],  minlength=3))\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_graphs,   batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(test_graphs,  batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "946b3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_DIM = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70147"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GATv2Conv, global_mean_pool, global_max_pool\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class EEGPhase3Model(nn.Module):\n",
    "    def __init__(self, in_dim=9, hidden=128, heads=4, layers=2, dropout=0.3, out_classes=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.bns    = nn.ModuleList()\n",
    "        d_in = in_dim\n",
    "        for _ in range(layers):\n",
    "            self.layers.append(GATv2Conv(d_in, hidden//heads, heads=heads, edge_dim=1, add_self_loops=False))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden))\n",
    "            d_in = hidden\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(hidden*2, hidden)\n",
    "        self.cls  = nn.Linear(hidden, out_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        if edge_attr is not None and edge_attr.dim() == 1:\n",
    "            edge_attr = edge_attr.unsqueeze(-1)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        for conv, bn in zip(self.layers, self.bns):\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        g = torch.cat([global_mean_pool(x, batch), global_max_pool(x, batch)], dim=-1)\n",
    "        g = F.relu(self.proj(g))\n",
    "        logits = self.cls(g)\n",
    "        return logits, g\n",
    "IN_DIM = train_graphs[0].x.size(1) \n",
    "print(\"IN_DIM =\", IN_DIM)   \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3 = EEGPhase3Model(in_dim=IN_DIM, hidden=128, heads=4, layers=2, dropout=0.3, out_classes=3).to(device)\n",
    "sum(p.numel() for p in model3.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2812496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=0.2279 | val_acc=0.9779 | val_f1=0.9560\n",
      "[Epoch 02] loss=0.0961 | val_acc=0.9857 | val_f1=0.9701\n",
      "[Epoch 03] loss=0.0669 | val_acc=0.9864 | val_f1=0.9716\n",
      "[Epoch 04] loss=0.0613 | val_acc=0.9860 | val_f1=0.9697\n",
      "[Epoch 05] loss=0.0489 | val_acc=0.9882 | val_f1=0.9750\n",
      "[Epoch 06] loss=0.0447 | val_acc=0.9857 | val_f1=0.9693\n",
      "[Epoch 07] loss=0.0355 | val_acc=0.9886 | val_f1=0.9753\n",
      "[Epoch 08] loss=0.0425 | val_acc=0.9908 | val_f1=0.9806\n",
      "[Epoch 09] loss=0.0350 | val_acc=0.9912 | val_f1=0.9811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def class_weights(graphs, ncls=3):\n",
    "    ys = [int(g.y.item()) for g in graphs]\n",
    "    cnt = np.bincount(ys, minlength=ncls).astype(np.float32)\n",
    "    w = cnt.max() / (cnt + 1e-6)\n",
    "    return torch.tensor(w, dtype=torch.float)\n",
    "\n",
    "cw = class_weights(train_graphs, ncls=3).to(device)\n",
    "opt = torch.optim.AdamW(model3.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loader(loader):\n",
    "    model3.eval()\n",
    "    ys, ps = [], []\n",
    "    for b in loader:\n",
    "        b = b.to(device)\n",
    "        logits, _ = model3(b)\n",
    "        ps.extend(logits.argmax(-1).cpu().numpy().tolist())\n",
    "        ys.extend(b.y.cpu().numpy().tolist())\n",
    "    acc = accuracy_score(ys, ps)\n",
    "    f1m = f1_score(ys, ps, average=\"macro\", zero_division=0)\n",
    "    rep = classification_report(ys, ps, labels=[0,1,2],\n",
    "                                target_names=[\"ADHD\",\"Schizophrenia\",\"Epilepsy\"], zero_division=0)\n",
    "    return acc, f1m, rep\n",
    "\n",
    "def train_one_epoch():\n",
    "    model3.train()\n",
    "    total = 0.0\n",
    "    for b in train_loader:\n",
    "        b = b.to(device)\n",
    "        if b.edge_attr is not None and b.edge_attr.dim()==1:\n",
    "            b.edge_attr = b.edge_attr.unsqueeze(-1)\n",
    "        logits, _ = model3(b)\n",
    "        loss = F.cross_entropy(logits, b.y, weight=cw)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model3.parameters(), 2.0)\n",
    "        opt.step()\n",
    "        total += loss.item() * b.num_graphs\n",
    "    return total / len(train_loader.dataset)\n",
    "\n",
    "best_f1, best_state, patience, wo = -1.0, None, 8, 0\n",
    "for epoch in range(1, 10):\n",
    "    tr_loss = train_one_epoch()\n",
    "    va_acc, va_f1, _ = eval_loader(val_loader)\n",
    "    print(f\"[Epoch {epoch:02d}] loss={tr_loss:.4f} | val_acc={va_acc:.4f} | val_f1={va_f1:.4f}\")\n",
    "    if va_f1 > best_f1:\n",
    "        best_f1, best_state, wo = va_f1, {k:v.detach().cpu() for k,v in model3.state_dict().items()}, 0\n",
    "    else:\n",
    "        wo += 1\n",
    "        if wo >= patience:\n",
    "            print(\"Early stopping.\"); break\n",
    "\n",
    "if best_state is not None:\n",
    "    model3.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3db884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST REPORT ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ADHD       1.00      1.00      1.00      2100\n",
      "Schizophrenia       0.98      0.97      0.97       270\n",
      "     Epilepsy       0.97      0.98      0.97       351\n",
      "\n",
      "     accuracy                           0.99      2721\n",
      "    macro avg       0.98      0.98      0.98      2721\n",
      " weighted avg       0.99      0.99      0.99      2721\n",
      "\n",
      "Test Acc=0.9919 | Test Macro-F1=0.9813\n",
      "Saved → outputs_phase3/phase3_eeg_gatv2.pth\n"
     ]
    }
   ],
   "source": [
    "te_acc, te_f1, te_rep = eval_loader(test_loader)\n",
    "print(\"=== TEST REPORT ===\")\n",
    "print(te_rep)\n",
    "print(f\"Test Acc={te_acc:.4f} | Test Macro-F1={te_f1:.4f}\")\n",
    "\n",
    "os.makedirs(\"outputs_phase3\", exist_ok=True)\n",
    "torch.save(model3.state_dict(), \"outputs_phase3/phase3_eeg_gatv2.pth\")\n",
    "print(\"Saved → outputs_phase3/phase3_eeg_gatv2.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c47ca160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → outputs_phase3/task2_fullbank_classonly.jsonl\n",
      "Example: {\n",
      "  \"true_disease\": \"ADHD\",\n",
      "  \"pred_disease\": \"ADHD\",\n",
      "  \"disease_probs\": {\n",
      "    \"ADHD\": 1.0,\n",
      "    \"Schizophrenia\": 6.748279712809335e-09,\n",
      "    \"Epilepsy\": 1.9434192033429554e-09\n",
      "  },\n",
      "  \"drug_class_probs\": {\n",
      "    \"ADHD\": 0.07944796979427338,\n",
      "    \"Schizophrenia\": 0.2082979828119278,\n",
      "    \"Epilepsy\": 0.4988584518432617,\n",
      "    \"Supplement\": 0.21339532732963562\n",
      "  }\n",
      "}  ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "Z = torch.load(\"outputs_phase3/drug_bank_Z.pt\", map_location=device)\n",
    "with open(\"outputs_phase3/drug_bank_label_to_indices.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    label_to_indices = json.load(f)\n",
    "\n",
    "\n",
    "label_names = [\"ADHD\", \"Schizophrenia\", \"Epilepsy\"]                \n",
    "drug_label_names = [\"ADHD\", \"Schizophrenia\", \"Epilepsy\", \"Supplement\"]  \n",
    "\n",
    "TAU = 0.1   \n",
    "\n",
    "model3.eval()\n",
    "\n",
    "def ensure_edge_attr(batch):\n",
    "    \"\"\"Ensure edge_attr exists and is [E,1] float, since GATv2Conv(edge_dim=1) is used.\"\"\"\n",
    "    if not hasattr(batch, \"edge_attr\") or batch.edge_attr is None:\n",
    "        E = batch.edge_index.size(1)\n",
    "        batch.edge_attr = torch.ones((E, 1), device=batch.edge_index.device, dtype=torch.float)\n",
    "    else:\n",
    "        ea = batch.edge_attr\n",
    "        if ea.dim() == 1:\n",
    "            batch.edge_attr = ea.view(-1, 1).float()\n",
    "        elif ea.dim() == 2 and ea.size(-1) != 1:\n",
    "            batch.edge_attr = ea[:, :1].float()\n",
    "        else:\n",
    "            batch.edge_attr = ea.float()\n",
    "    return batch\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_model3(batch):\n",
    "    \"\"\"Call model3 no matter if it expects (data) or (x,edge_index,edge_attr,batch).\"\"\"\n",
    "    try:\n",
    "        out = model3(batch)\n",
    "        if isinstance(out, tuple) and len(out) == 2:\n",
    "            return out\n",
    "        raise TypeError(\"Model returned unexpected output shape\")\n",
    "    except TypeError:\n",
    "        b = ensure_edge_attr(batch)\n",
    "        return model3(b.x, b.edge_index, b.edge_attr, b.batch)\n",
    "\n",
    "@torch.no_grad()\n",
    "def aggregate_class_probs(probs_row: torch.Tensor):\n",
    "    \"\"\"\n",
    "    probs_row: [M] per-drug probabilities\n",
    "    returns: dict class -> sum of probs over drugs of that class\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for lab in drug_label_names:\n",
    "        idxs = label_to_indices.get(lab, [])\n",
    "        out[lab] = float(probs_row[idxs].sum().item()) if idxs else 0.0\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_full(batch):\n",
    "    \"\"\"\n",
    "    For a batch of EEG graphs:\n",
    "      - Get disease prediction (3-class)\n",
    "      - Map EEG embedding to full drug bank probs (size M)\n",
    "      - Aggregate to class-level probs (ADHD/Sch/Epi/Supplement)\n",
    "    \"\"\"\n",
    "    logits, g = run_model3(batch)                            \n",
    "    probs_disease = F.softmax(logits, dim=1)                   \n",
    "    scores, probs_drugs = scores_for_all_drugs(g, Z, tau=TAU)  \n",
    "\n",
    "    out_list = []\n",
    "    for i in range(probs_drugs.size(0)):\n",
    "        true_lbl = int(batch.y[i].item()) if hasattr(batch, \"y\") else None\n",
    "        pred_lbl = int(torch.argmax(probs_disease[i]).item())\n",
    "        out_list.append({\n",
    "            \"true_disease\": label_names[true_lbl] if true_lbl is not None and true_lbl < len(label_names) else None,\n",
    "            \"pred_disease\": label_names[pred_lbl],\n",
    "            \"disease_probs\": {\n",
    "                \"ADHD\": float(probs_disease[i,0]),\n",
    "                \"Schizophrenia\": float(probs_disease[i,1]),\n",
    "                \"Epilepsy\": float(probs_disease[i,2]),\n",
    "            },\n",
    "            \n",
    "            \"drug_class_probs\": aggregate_class_probs(probs_drugs[i]),\n",
    "        })\n",
    "    return out_list\n",
    "\n",
    "\n",
    "all_records = []\n",
    "for b in test_loader:\n",
    "    b = b.to(device)\n",
    "    all_records.extend(predict_full(b))\n",
    "\n",
    "os.makedirs(\"outputs_phase3\", exist_ok=True)\n",
    "out_path = \"outputs_phase3/task2_fullbank_classonly.jsonl\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in all_records:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Saved → {out_path}\")\n",
    "print(\"Example:\", json.dumps(all_records[0], ensure_ascii=False, indent=2)[:1200], \" ...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
